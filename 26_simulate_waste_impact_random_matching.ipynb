{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ca1a28",
   "metadata": {},
   "source": [
    "# Notebook 26 - Simulate Waste Impact with Random Matching\n",
    "\n",
    "This notebook evaluates the effectiveness of a random product matching strategy by simulating how much food waste could have been avoided using randomly selected matches for each store-ingredient pair.\n",
    "\n",
    "## Objectives\n",
    "- Load random matches generated in Notebook 25\n",
    "- Merge recipe/store context for alignment\n",
    "- Join with waste logs using concept-level linking\n",
    "- Aggregate avoided waste (items + value) per store\n",
    "- Save results for benchmarking in Notebook 24\n",
    "\n",
    "## Inputs\n",
    "- matching_scored/matching_matrix_random.csv\n",
    "- recipe_ranking/recipe_store_ranked.csv\n",
    "- variant_exports/recipes_with_variants.csv\n",
    "- cleaned_data/waste_with_concept.csv\n",
    "\n",
    "## Output\n",
    "- waste_simulation/waste_impact_random.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f671a048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:\n",
      "- Random Matches: (4, 8)\n",
      "- Ranked Recipes: (4, 6)\n",
      "- Recipes: (6, 8)\n",
      "- Waste: (18382, 16)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define folders\n",
    "matching_folder = \"matching_scored\"\n",
    "ranking_folder = \"recipe_ranking\"\n",
    "variant_folder = \"variant_exports\"\n",
    "waste_folder = \"cleaned_data\"\n",
    "output_folder = \"waste_simulation\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Define files\n",
    "match_file = os.path.join(matching_folder, \"matching_matrix_random.csv\")\n",
    "ranked_file = os.path.join(ranking_folder, \"recipe_store_ranked.csv\")\n",
    "recipes_file = os.path.join(variant_folder, \"recipes_with_variants.csv\")\n",
    "waste_file = os.path.join(waste_folder, \"waste_with_concept.csv\")\n",
    "\n",
    "# Load datasets\n",
    "df_matches = pd.read_csv(match_file)\n",
    "df_ranked = pd.read_csv(ranked_file)\n",
    "df_recipes = pd.read_csv(recipes_file)\n",
    "df_waste = pd.read_csv(waste_file)\n",
    "\n",
    "print(\"Loaded:\")\n",
    "print(f\"- Random Matches: {df_matches.shape}\")\n",
    "print(f\"- Ranked Recipes: {df_ranked.shape}\")\n",
    "print(f\"- Recipes: {df_recipes.shape}\")\n",
    "print(f\"- Waste: {df_waste.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c04fb35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge successful. 'recipe' column restored to df_matches.\n"
     ]
    }
   ],
   "source": [
    "# Ensure row_id exists\n",
    "df_matches[\"row_id\"] = pd.to_numeric(df_matches[\"row_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "df_recipes[\"row_id\"] = pd.to_numeric(df_recipes[\"row_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Normalize ingredient names\n",
    "df_matches[\"ingredient\"] = df_matches[\"ingredient\"].astype(str).str.strip().str.lower()\n",
    "df_recipes[\"ingredient\"] = df_recipes[\"ingredient\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Merge recipe names back into df_matches using row_id and ingredient\n",
    "df_matches = df_matches.merge(\n",
    "    df_recipes[[\"row_id\", \"ingredient\", \"recipe\"]],\n",
    "    on=[\"row_id\", \"ingredient\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Confirm success\n",
    "assert \"recipe\" in df_matches.columns, \"Merge failed: 'recipe' column missing\"\n",
    "print(\"Merge successful. 'recipe' column restored to df_matches.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5bc8320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployed random matches: (4, 10)\n"
     ]
    }
   ],
   "source": [
    "# Normalize concept field for join\n",
    "df_matches[\"product_concept\"] = df_matches[\"product_concept\"].astype(str).str.strip().str.lower()\n",
    "df_waste[\"product_concept\"] = df_waste[\"product_concept\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# Filter to deployed recipe-store pairs only\n",
    "deployable_pairs = df_ranked[[\"store\", \"recipe\"]].drop_duplicates()\n",
    "df_deployed = df_matches.merge(deployable_pairs, on=[\"store\", \"recipe\"], how=\"inner\")\n",
    "print(\"Deployed random matches:\", df_deployed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ae25c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix any inconsistent store column in df_waste BEFORE merge\n",
    "df_waste = df_waste.rename(columns={col: \"Store\" for col in df_waste.columns if col.lower() == \"store\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d2b7ebb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulated random impact matches: (610, 25)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>product_concept</th>\n",
       "      <th>Items wasted</th>\n",
       "      <th>Value wasted</th>\n",
       "      <th>recipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>nan</td>\n",
       "      <td>6</td>\n",
       "      <td>5.94</td>\n",
       "      <td>Greek Yogurt &amp; Honey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1024</td>\n",
       "      <td>nan</td>\n",
       "      <td>4</td>\n",
       "      <td>3.16</td>\n",
       "      <td>Greek Yogurt &amp; Honey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1024</td>\n",
       "      <td>nan</td>\n",
       "      <td>8</td>\n",
       "      <td>15.92</td>\n",
       "      <td>Greek Yogurt &amp; Honey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1024</td>\n",
       "      <td>nan</td>\n",
       "      <td>2</td>\n",
       "      <td>2.30</td>\n",
       "      <td>Greek Yogurt &amp; Honey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1024</td>\n",
       "      <td>nan</td>\n",
       "      <td>2</td>\n",
       "      <td>4.18</td>\n",
       "      <td>Greek Yogurt &amp; Honey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store product_concept  Items wasted  Value wasted                recipe\n",
       "0   1024             nan             6          5.94  Greek Yogurt & Honey\n",
       "1   1024             nan             4          3.16  Greek Yogurt & Honey\n",
       "2   1024             nan             8         15.92  Greek Yogurt & Honey\n",
       "3   1024             nan             2          2.30  Greek Yogurt & Honey\n",
       "4   1024             nan             2          4.18  Greek Yogurt & Honey"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Perform concept-level join to match deployed products to waste records\n",
    "df_simulated = df_waste.merge(\n",
    "    df_deployed,\n",
    "    left_on=[\"Store\", \"product_concept\"],\n",
    "    right_on=[\"store\", \"product_concept\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Simulated random impact matches:\", df_simulated.shape)\n",
    "display(df_simulated[[\"Store\", \"product_concept\", \"Items wasted\", \"Value wasted\", \"recipe\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c57abea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and reassigned 'store' column safely.\n"
     ]
    }
   ],
   "source": [
    "df_waste = df_waste.rename(columns={col: \"Store\" for col in df_waste.columns if col.lower() == \"store\"})\n",
    "\n",
    "# Find all columns named 'store' (case-insensitive)\n",
    "store_col_idx = [i for i, c in enumerate(df_simulated.columns) if c.lower() == \"store\"]\n",
    "\n",
    "# Check we have at least two (waste + deployed)\n",
    "if len(store_col_idx) < 2:\n",
    "    raise ValueError(\"Expected at least two 'store' columns in df_simulated.\")\n",
    "\n",
    "# Extract second one (from df_deployed) as a temp variable\n",
    "store_series = df_simulated.iloc[:, store_col_idx[1]]\n",
    "\n",
    "# Drop *by position* instead of name to avoid pandas re-aliasing\n",
    "df_simulated.drop(df_simulated.columns[store_col_idx], axis=1, inplace=True)\n",
    "\n",
    "# Assign clean version back to correct name\n",
    "df_simulated[\"store\"] = pd.to_numeric(store_series, errors=\"coerce\").astype(\"Int64\")\n",
    "assert df_simulated[\"store\"].ndim == 1\n",
    "\n",
    "print(\"Cleaned and reassigned 'store' column safely.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8ae41da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved simulated waste impact (random matching) to: waste_simulation\\waste_impact_random.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>items_wasted</th>\n",
       "      <th>value_wasted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1024</td>\n",
       "      <td>327</td>\n",
       "      <td>528.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1090</td>\n",
       "      <td>166</td>\n",
       "      <td>371.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3340</td>\n",
       "      <td>275</td>\n",
       "      <td>421.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4255</td>\n",
       "      <td>429</td>\n",
       "      <td>677.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store  items_wasted  value_wasted\n",
       "0   1024           327        528.54\n",
       "1   1090           166        371.52\n",
       "2   3340           275        421.81\n",
       "3   4255           429        677.31"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Rename for consistency\n",
    "df_simulated = df_simulated.rename(columns={\n",
    "    \"Items wasted\": \"items_wasted\",\n",
    "    \"Value wasted\": \"value_wasted\"\n",
    "})\n",
    "\n",
    "# Aggregate total waste potentially avoided per store\n",
    "df_impact = df_simulated.groupby(\"store\").agg({\n",
    "    \"items_wasted\": \"sum\",\n",
    "    \"value_wasted\": \"sum\"\n",
    "}).reset_index()\n",
    "\n",
    "# Save results\n",
    "output_file = os.path.join(output_folder, \"waste_impact_random.csv\")\n",
    "df_impact.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Saved simulated waste impact (random matching) to:\", output_file)\n",
    "display(df_impact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c00ba31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
