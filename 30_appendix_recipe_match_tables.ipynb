{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571dce98",
   "metadata": {},
   "source": [
    "# Notebook 30 - Appendix Recipe Match Tables\n",
    "\n",
    "This notebook exports detailed match tables per recipe to support transparency in the appendix. For each recipe, it lists:\n",
    "\n",
    "- Ingredients and their candidate product matches\n",
    "- Matching scores (semantic, fuzzy)\n",
    "- Waste-aware priority flags\n",
    "- Matched store and article information (if available)\n",
    "\n",
    "These tables can be included in the appendix or published as supporting materials.\n",
    "\n",
    "**Objectives**\n",
    "- Load semantic and fuzzy match results\n",
    "- Merge with ingredient context and product metadata\n",
    "- Export per-recipe CSV files for transparency\n",
    "\n",
    "**Inputs**\n",
    "- matching_scored/matching_matrix_semantic.csv\n",
    "- matching_scored/matching_matrix_fuzzy.csv\n",
    "- variant_exports/recipes_with_variants.csv\n",
    "- cleaned_data/products_with_priority.csv\n",
    "\n",
    "**Outputs**\n",
    "- appendix_tables/semantic_matches/recipe_<name>.csv\n",
    "- appendix_tables/fuzzy_matches/recipe_<name>.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed2c82dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files loaded and normalized.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define folders\n",
    "match_folder = \"matching_scored\"\n",
    "variant_folder = \"variant_exports\"\n",
    "priority_folder = \"cleaned_data\"\n",
    "output_folder_semantic = os.path.join(\"appendix_tables\", \"semantic_matches\")\n",
    "output_folder_fuzzy = os.path.join(\"appendix_tables\", \"fuzzy_matches\")\n",
    "os.makedirs(output_folder_semantic, exist_ok=True)\n",
    "os.makedirs(output_folder_fuzzy, exist_ok=True)\n",
    "\n",
    "# Define files\n",
    "semantic_file = os.path.join(match_folder, \"matching_matrix_semantic.csv\")\n",
    "fuzzy_file = os.path.join(match_folder, \"matching_matrix_fuzzy.csv\")\n",
    "recipes_file = os.path.join(variant_folder, \"recipes_with_variants.csv\")\n",
    "products_file = os.path.join(priority_folder, \"products_with_priority.csv\")\n",
    "\n",
    "# Load data\n",
    "df_semantic = pd.read_csv(semantic_file)\n",
    "df_fuzzy = pd.read_csv(fuzzy_file)\n",
    "df_recipes = pd.read_csv(recipes_file)\n",
    "df_products = pd.read_csv(products_file)\n",
    "\n",
    "# Fix missing row_id if needed\n",
    "if \"row_id\" not in df_recipes.columns:\n",
    "    df_recipes = df_recipes.reset_index(drop=False).rename(columns={\"index\": \"row_id\"})\n",
    "\n",
    "# Normalize keys\n",
    "for df in [df_semantic, df_fuzzy, df_recipes]:\n",
    "    df[\"row_id\"] = pd.to_numeric(df[\"row_id\"], errors=\"coerce\").astype(\"Int64\")\n",
    "    df[\"ingredient\"] = df[\"ingredient\"].astype(str).str.strip().str.lower()\n",
    "df_recipes[\"recipe\"] = df_recipes[\"recipe\"].astype(str).str.strip()\n",
    "\n",
    "print(\"All files loaded and normalized.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "791ac8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Merged recipe and product context into semantic and fuzzy match tables.\n"
     ]
    }
   ],
   "source": [
    "# Merge recipe names into match tables\n",
    "df_products = df_products.rename(columns={\"article\": \"product_article\"})\n",
    "\n",
    "df_semantic = df_semantic.merge(\n",
    "    df_recipes[[\"row_id\", \"ingredient\", \"recipe\"]],\n",
    "    on=[\"row_id\", \"ingredient\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "df_fuzzy = df_fuzzy.merge(\n",
    "    df_recipes[[\"row_id\", \"ingredient\", \"recipe\"]],\n",
    "    on=[\"row_id\", \"ingredient\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# Merge in product metadata (for waste/markdown flags)\n",
    "df_products[\"product_article\"] = pd.to_numeric(df_products[\"product_article\"], errors=\"coerce\")\n",
    "for df in [df_semantic, df_fuzzy]:\n",
    "    df[\"product_article\"] = pd.to_numeric(df[\"product_article\"], errors=\"coerce\")\n",
    "    df.merge(df_products[[\"product_article\", \"product_concept\", \"priority_score\", \"waste_flag\", \"markdown_flag\"]],\n",
    "             on=\"product_article\", how=\"left\")\n",
    "\n",
    "print(\" Merged recipe and product context into semantic and fuzzy match tables.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bf357d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported per-recipe match tables for semantic and fuzzy results.\n"
     ]
    }
   ],
   "source": [
    "# Export detailed per-recipe match tables\n",
    "for recipe in df_recipes[\"recipe\"].unique():\n",
    "    # Filter rows for this recipe\n",
    "    df_sem = df_semantic[df_semantic[\"recipe\"] == recipe]\n",
    "    df_fuz = df_fuzzy[df_fuzzy[\"recipe\"] == recipe]\n",
    "\n",
    "    # Clean recipe name for file-safe export\n",
    "    file_safe = recipe.lower().replace(\"&\", \"and\").replace(\" \", \"_\").replace(\"/\", \"_\").replace(\"'\", \"\").replace(\",\", \"\")\n",
    "    \n",
    "    # Save to folder\n",
    "    df_sem.to_csv(os.path.join(output_folder_semantic, f\"recipe_{file_safe}.csv\"), index=False)\n",
    "    df_fuz.to_csv(os.path.join(output_folder_fuzzy, f\"recipe_{file_safe}.csv\"), index=False)\n",
    "\n",
    "print(\"Exported per-recipe match tables for semantic and fuzzy results.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
